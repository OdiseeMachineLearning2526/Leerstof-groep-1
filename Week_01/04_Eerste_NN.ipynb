{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c82bef3d-5a9a-4627-ba46-35fbd0515457",
   "metadata": {},
   "source": [
    "# Een eerste neuraal netwerk\n",
    "\n",
    "In deze notebook wordt getoond hoe een neuraal netwerk opgebouwd kan worden met Pytorch.\n",
    "Hierbij wordt er dieper ingegaan op de keuzes van hyperparameters.\n",
    "\n",
    "In de eerste codecell importeren we de nodige functionaliteiten van pytorch. \n",
    "Daarna maken we ook een aantal variabelen aan die we gaan gebruiken voor het aanmaken van het netwerk.\n",
    "De betekenis van deze parameters is:\n",
    "* input_size: aantal features in de dataset\n",
    "* hidden_size: aantal neuronen in de enkele hidden laag\n",
    "* output_size: aantal neuronen in de outputlaag\n",
    "* learning_rate: de learning rate van de optimizer\n",
    "* epochs: aantal keer dat de volledige dataset gebruikt wordt voor training\n",
    "* batch_size: hoeveel inputs er gegroepeerd worden voordat de gewichten geoptimaliseerd worden\n",
    "* dropout_rate: het aantal connecties dat op een willekeurige manier zal wegvallen\n",
    "\n",
    "Voor de input_size heb je meestal geen keuze. Deze wordt bepaald door de gegeven dataset. Elke feature van de input wordt namelijk gematchet op een neuron in de inputlayer.\n",
    "Ook de output_size wordt bepaald door het probleem. Dit is de gewenste output dus:\n",
    "* Bij een regressieprobleem is er 1 neuron per ter voorspellen waarde\n",
    "* Bij classificatie is er 1 neuron per klasse\n",
    "    * In het geval van 2 klassen kan je gebruik maken van 1 klasse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3da142a-42e9-4ab6-8fbf-05abfd0c9aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Configuratie\n",
    "input_size = 20       # Aantal ingangsfeatures\n",
    "hidden_size = 64      # Grootte van de verborgen lagen\n",
    "output_size = 2       # Aantal klassen (voor classificatie)\n",
    "learning_rate = 0.001 # Learning rate\n",
    "epochs = 50           # Aantal epochs\n",
    "batch_size = 32       # Batch grootte\n",
    "dropout_rate = 0.5    # Dropout rate voor regularisatie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8309009b-ebd9-47a8-a770-fe093117ac40",
   "metadata": {},
   "source": [
    "Na het bepalen van de configuratie kan de dataset gemaakt worden. Dit gebeurd met de make_classification functie van scikit-learn om met random data te werken.\n",
    "In dit voorbeeld is er gekozen voor een classificatieprobleem met 2 klassen.\n",
    "\n",
    "Deze dataset wordt daarna gesplits in features en labels, en gepslitst in trainings- en testdata.\n",
    "In pytorch ziet dit eruit als volgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173753c0-6a6a-4945-96b3-b46810226889",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "070760c9-cf91-47d7-8388-6bb9d2bec67a",
   "metadata": {},
   "source": [
    "## Methode 1: Klasieke techniek om NN op te stellen met pytorch\n",
    "Hierna kan het neuraal netwerk aangemaakt worden.\n",
    "Eerst gaan we werken met de klassieke en meest manuele manier.\n",
    "Dit gaat misschien niet de meest beknopte manier zijn maar geeft je wel de meeste mogelijkheden om het model en trainingsproces aan te passen aan je noden.\n",
    "\n",
    "De klassieke techniek met pytorch is om een klasse te maken die overerft van de Module-klasse.\n",
    "In deze klasse moet je de volgende zaken aanpassen:\n",
    "\n",
    "* In de constructor van deze klasse maak je de nodige lagen aan van het neuraal netwerk.\n",
    "* In de forward functie van de klasse geef je dan hoe deze lagen aan elkaar gekoppeld worden.\n",
    "\n",
    "In onderstaande voorbeeld worden vier eenvoudige lagen aangemaakt (1 voor de inputs, 2 voor de hiden layers en 1 voor de output layer). De activatiefunctie wordt toegevoegd in de forward functie. In het model hieronder is er gekozen om te werken met een Relu-functie na de input en hidden layer. De output layer bevat een standaard lienaire functie. Dit omdat pytorch beschikt over een speciale loss-functie om een sigmoid/softmax in de output layer overbodig te maken wat efficienter is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b767174a-980a-4473-ba01-7e7f8bcc8d36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e928c7c0-eb19-4d86-a8d9-253b4cd66933",
   "metadata": {},
   "source": [
    "Om dit model te trainen moet er eerst bepaald worden wat er moet geoptimaliseerd worden.\n",
    "Dit is **de loss-functie** die moet geminimaliseerd worden.\n",
    "Dit wordt ook bepaald door het op te lossen probleem, namelijk:\n",
    "\n",
    "* Bij regressie wordt er typisch gekozen voor Mean-Squared-Error (noemt in pytorch MSELoss) of Mean-Squared-Error\n",
    "* Bij classificatie wordt er gekozen voor\n",
    "    * BCEWithLogitsLoss bij binaire classificatie (BCE staat voor Binary Cross Entropy )\n",
    "        * Hierbij moet geen sigmoid activatiefunctie gebruikt worden want dit is reeds ingebouwd in de loss-functie\n",
    "        * Indien er toch een sigmoid-functie gebruikt wordt in de output-layer: BCELoss\n",
    "    * CrossEntropy in het geval van multi-class classification (meerdere opties maar slechts 1 klasse te kiezen)\n",
    "    * BCEWithLogitsLoss bij multilabel classificatie\n",
    "        *  Aangezien elk outputneuron een binaire classificatie is\n",
    "     \n",
    "Daarna wordt de training uitgevoerd door het aantal epoch keer de dataset te gebruiken om de gewichten te optimaliseren.\n",
    "Hiervoor moet er per epoch het volgende uitgevoerd worden:\n",
    "* Zet het model in een trainingsmodus\n",
    "* Geef de data aan het model en doe per batch\n",
    "    * Bereken de outputs\n",
    "    * Bereken de error tussen de outputs en gewenste labels\n",
    "    * Voer backwards propagation uit om gewichten up te daten\n",
    "* Zet het model in een evaluatie modus\n",
    "* Bereken de totale loss op de test-date\n",
    "    *  Dit wordt gebruikt om de prestaties van het model op te volgen en kan gebruikt worden om het trainen eerder te stoppen indien er overfitting gedetecteerd wordt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b3729e-39c3-49ad-97df-3473192454de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f2b1e94d-dd6b-4ea9-8007-0b193deb0428",
   "metadata": {},
   "source": [
    "De resultaten van het trainingsproces kunnen geplot worden met onderstaande code\n",
    "De x-as stelt de prestaties van het model voor doorheen het trainingsproces.\n",
    "Het resulteren model heeft dus de prestaties in de laatste epoch.\n",
    "Deze figuur kan gebruikt worden om\n",
    "* De stabiliteit van het model te valideren\n",
    "    * Een onstabiel model (met veel variatie in de output zal niet goed generaliseren)\n",
    "* Het aantal gekozen epochs/learning rate te valideren\n",
    "    * Als de loss-functie nog snel daalt moet het aantal epochs of de learning rate verhoogd worden\n",
    "* Underfitting detecteren\n",
    "    * Als de error nog te hoog is voor je doelstelling is ofwel het model niet complex genoeg of de data niet goed genoeg \n",
    "* Overfitting detecteren\n",
    "    * Als er een punt is waarop de test-loss (error op de testdata) terug toeneemt en de train-loss verder daalt. Dan treedt er vanaf die epoch overfitting op\n",
    "    * Dit kan vermeden worden door meer regularisatie toe te voegen of de complexiteit van het model te verlagen\n",
    "    * Het aantal epochs reduceren tot dit punt is niet goed want dan verlaag je de prestaties van je model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837f28b1-2bd9-43d9-ac02-c639fd78784d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e1ac013-d0d1-4e99-8348-a38b359edd1e",
   "metadata": {},
   "source": [
    "## Methode 2: Kortere maar minder flexibele schrijfwijze\n",
    "\n",
    "Aangezien bovenstaande model een standaard structuur heeft kan het ook herschreven worden als een functioneel model.\n",
    "In dit geval ziet de code eruit als volgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294dfbae-9750-434a-bea4-81700746a25a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9fe6ce99-b5fe-49ea-b89b-956eb2b3dfae",
   "metadata": {},
   "source": [
    "Hierbij is de opbouw van het model vereenvoudigd maar **de traningslus moet nog steeds voluit geschreven worden**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42364728-03ac-4b14-9aa6-a6478c4121b4",
   "metadata": {},
   "source": [
    "## Methode 3: Keras\n",
    "\n",
    "Een derde manier om de code te schrijven is door middel van **Keras**. \n",
    "Deze manier van code schrijven is identiek aan hoe het eruitziet inden er gebruik gemaakt wordt van **Tensorflow**.\n",
    "Met keras kan zowel de opbouw van het model als de trainingslus sterk vereenvoudigd worden.\n",
    "\n",
    "Merk op dat hieronder **wel een softmax nodig is** omdat de standaard crossentropy functies van keras/tensorflow dit vereisen. \n",
    "Daarnaast is het ook interessant dat Keras een summary kan uitprinten van een model om een overzicht te krijgen van de architectuur en het aantal parameters dat in elke laag moet getrained worden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1a1869-51a1-4de6-85bc-9d57257a14e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6b55aa74-2eaa-47db-807c-e8c654633d1e",
   "metadata": {},
   "source": [
    "## Oefening 1: Binaire classificatie\n",
    "\n",
    "Train een feed-forward neurale netwerk voor binaire classificatie met behulp van de make_classification functie van sklearn om een dataset te genereren.\n",
    "\n",
    "Gebruik een eenvoudig netwerk met één verborgen laag van 64 neuronen en een sigmoid activatiefunctie.\n",
    "Schrijf je code aan de hand van Keras\n",
    "\n",
    "**Uitbreiding (ook voor alle andere oefeningen)** Oefen ook de andere code-schrijfwijzen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae1adfe-ab78-447b-bbb5-d44f91b55d89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3b3cad50-826b-4657-a986-d88e147085df",
   "metadata": {},
   "source": [
    "## Oefening 2: Multiklasse classificatie met Iris Dataset\n",
    "\n",
    "Train een feed-forward neurale netwerk voor multiklasse classificatie met behulp van de load_iris functie van sklearn om de Iris dataset te laden.\n",
    "Gebruik een netwerk met drie verborgen laag van 32 neuronen en een softmax activatiefunctie.\n",
    "\n",
    "Schrijf je code aan de hand van nn.Sequential (tweede schrijfwijze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a979d880-76b2-4330-b420-abff05a9b55b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1d01b6c2-015e-4746-9ce0-0fc75bb05adb",
   "metadata": {},
   "source": [
    "## Oefening 3: Regressie met Diabetes Dataset\n",
    "\n",
    "Train een feed-forward neurale netwerk voor regressie met behulp van de load_diabetes functie van sklearn om de Diabetes dataset te laden.\n",
    "Gebruik een netwerk met één verborgen laag van 64 neuronen en een gepaste activatiefunctie\n",
    "\n",
    "Gebruik voor deze oefeningen de klassieke pytorch schrijfwijze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3eff6a9-f1d3-4787-9574-228c4caa7aad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b077ba8b-1609-4242-8928-6feda44c65b3",
   "metadata": {},
   "source": [
    "## Oefening 4: Binaire classificatie met Moons Dataset\n",
    "\n",
    "Train een feed-forward neurale netwerk voor binaire classificatie met behulp van de make_moons functie van sklearn om een maanvormige dataset te genereren.\n",
    "Pas in deze oefening l2-regularisatie toe ipv dropout.\n",
    "\n",
    "Gebruik de keras notatie met een pytorch backend (code hiervoor al gegeven hieronder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f45a38e-3cb9-41de-be71-1a9cba1a807e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cf9ca70b-690d-40c6-930b-9068af2a65ef",
   "metadata": {},
   "source": [
    "## Oefening 5: Multilabel classificatie met Circles Dataset\n",
    "\n",
    "Train een feed-forward neurale netwerk voor multilabel classificatie met behulp van de make_circles functie van sklearn om een dataset met cirkelvormige klassen te genereren.\n",
    "\n",
    "Maak gebruik van nn.Module inheritance om dit model te schrijven en zorg voor regularisation door gebruik te maken van de L2-norm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccf6aa9-2406-4938-bd02-c9b40901b2c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
