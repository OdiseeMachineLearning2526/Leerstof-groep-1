{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73e730cc-69c0-4b82-bb58-25a163fa4aad",
   "metadata": {},
   "source": [
    "# GAN met Fashion MNIST\n",
    "\n",
    "In deze notebook gaan we opnieuw beelden genereren op basis van de Fashin MNIST dataset, net zoals in de vorige notebook over variational autoencoders (VAE). \n",
    "Hierbij moeten we een generator en discriminator opstellen.\n",
    "\n",
    "## Importeren van packages en dataset\n",
    "\n",
    "Eerst importeren we alle benodigde Python-bibliotheken voor het bouwen, trainen en visualiseren van onze VAE.\n",
    "We gebruiken Pytorch voor het bouwen van het neurale netwerk, matplotlib voor visualisaties en NumPy voor numerieke berekeningen.\n",
    "Daarna laden we de Fashion MNIST dataset, normaliseren de pixelwaarden naar de range [-1,1] \n",
    "en splitsen de dataset in een trainings- en testset. We gebruiken DataLoader om mini-batches te maken voor training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1737c9cf-73df-433c-95b1-aa0c9e36f383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data geladen en DataLoader klaar.\n"
     ]
    }
   ],
   "source": [
    "# Importeren van benodigde bibliotheken\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Controleer of er een GPU beschikbaar is, zo niet gebruik de CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Data-transformatie: normaliseer de afbeeldingen zodat de pixelwaarden tussen -1 en 1 liggen\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Converteert beeld naar tensor\n",
    "])\n",
    "\n",
    "# FashionMNIST dataset downloaden en laden\n",
    "train_dataset = datasets.FashionMNIST(root='./data', train=True, transform=transform, download=True)\n",
    "\n",
    "# DataLoader voor batches van de trainingsdata\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "print(\"Data geladen en DataLoader klaar.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fe9ec8-a50e-43bf-beb2-6512baea7425",
   "metadata": {},
   "source": [
    "## Generator\n",
    "\n",
    " Deze cel definieert de generator die een random vector van ruis (latent vector) gebruikt om een afbeelding van 28x28 pixels te genereren. Het netwerk bestaat uit vier volledig verbonden lagen met ReLU-activatie, gevolgd door een Tanh activatie om de output te normaliseren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "874fb7ab-4bd0-4f04-af4f-f2d83ca3f8d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=100, out_features=256, bias=True)\n",
      "  (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): LeakyReLU(negative_slope=0.2)\n",
      "  (3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (4): Linear(in_features=256, out_features=512, bias=True)\n",
      "  (5): LeakyReLU(negative_slope=0.2)\n",
      "  (6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (7): Linear(in_features=512, out_features=1024, bias=True)\n",
      "  (8): LeakyReLU(negative_slope=0.2)\n",
      "  (9): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (10): Linear(in_features=1024, out_features=784, bias=True)\n",
      "  (11): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 100\n",
    "\n",
    "generator = nn.Sequential(\n",
    "    nn.Linear(latent_dim, 256),\n",
    "    nn.BatchNorm1d(256),  # 2e best practice in CNN/GAN - stabieler leerproces\n",
    "    nn.LeakyReLU(0.2),     # best practice in GAN - vermeidt dode neuronen\n",
    "    nn.BatchNorm1d(256),\n",
    "    nn.Linear(256, 512),\n",
    "    nn.LeakyReLU(0.2),     # best practice in GAN\n",
    "    nn.BatchNorm1d(512),\n",
    "    nn.Linear(512, 1024),\n",
    "    nn.LeakyReLU(0.2),     # best practice in GAN\n",
    "    nn.BatchNorm1d(1024),\n",
    "    nn.Linear(1024, 28*28), # 28 * 28 pixels -> dimensies van onze trainingsimages\n",
    "    nn.Sigmoid()\n",
    ").to(device)\n",
    "\n",
    "print(generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcf2452-9b43-4d32-aad2-54b6b5f935a8",
   "metadata": {},
   "source": [
    "## Discriminator\n",
    "\n",
    "Deze cel definieert de discriminator, die een afbeelding van 28x28 pixels als invoer ontvangt en een enkele waarde teruggeeft die aangeeft of de afbeelding echt is (uit de dataset) of vals (gegenereerd door de generator). Het netwerk bestaat uit vier volledig verbonden lagen met LeakyReLU-activatie en dropout om overfitting te voorkomen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0bbe85dc-37df-4501-9767-b5636cf04030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=784, out_features=1024, bias=True)\n",
      "  (1): LeakyReLU(negative_slope=0.2)\n",
      "  (2): Dropout(p=0.3, inplace=False)\n",
      "  (3): Linear(in_features=1024, out_features=512, bias=True)\n",
      "  (4): LeakyReLU(negative_slope=0.2)\n",
      "  (5): Dropout(p=0.3, inplace=False)\n",
      "  (6): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (7): LeakyReLU(negative_slope=0.2)\n",
      "  (8): Dropout(p=0.3, inplace=False)\n",
      "  (9): Linear(in_features=256, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "discr_in_dim = 28*28\n",
    "discriminator = nn.Sequential(\n",
    "    nn.Linear(discr_in_dim, 1024),\n",
    "    nn.LeakyReLU(0.2),   \n",
    "    nn.Dropout(0.3),\n",
    "    nn.Linear(1024, 512),\n",
    "    nn.LeakyReLU(0.2),   \n",
    "    nn.Dropout(0.3),\n",
    "    nn.Linear(512, 256),\n",
    "    nn.LeakyReLU(0.2),   \n",
    "    nn.Dropout(0.3),\n",
    "    nn.Linear(256, 1), # dit is 1 omdat we binaire classificatie doen\n",
    ").to(device)\n",
    "\n",
    "print(discriminator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a07f9a-1b9d-4548-867f-1c7e72369ecd",
   "metadata": {},
   "source": [
    "## Loss functions\n",
    "\n",
    "In deze cel worden de verliesfunctie en de optimalizers voor de generator en discriminator gedefinieerd. We gebruiken binaire cross-entropy (BCELoss) als verliesfunctie en de Adam-optimizer voor zowel de generator als de discriminator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d6f3fcc3-2f36-4882-81ef-75cdeccbb41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss() # dit is de loss functie voor binaire classificatie van de discriminator\n",
    "#-> geen loss-functie voor generator nodig want de output gaat eerst door de descriminator\n",
    "\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=0.001)\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f861192-bcd6-4ea3-8b46-d668028f696c",
   "metadata": {},
   "source": [
    "## Trainen van het GAN model\n",
    "\n",
    "De discriminator wordt getraind met zowel echte als gegenereerde afbeeldingen om te leren onderscheid te maken tussen de twee, terwijl de generator wordt getraind om betere afbeeldingen te genereren die de discriminator niet kan onderscheiden van echte. Voor elke epoch printen we het verlies van zowel de generator als de discriminator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dc0d4d1a-46a5-40d3-b256-0fbf3ec86189",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], d_loss: 0.0434, g_loss: 11.3034\n",
      "Epoch [2/10], d_loss: 0.0275, g_loss: 6.8369\n",
      "Epoch [3/10], d_loss: 0.3224, g_loss: 4.4642\n",
      "Epoch [4/10], d_loss: 0.0764, g_loss: 3.6162\n",
      "Epoch [5/10], d_loss: 0.4535, g_loss: 7.0837\n",
      "Epoch [6/10], d_loss: 0.0601, g_loss: 6.5621\n",
      "Epoch [7/10], d_loss: 0.0938, g_loss: 2.8669\n",
      "Epoch [8/10], d_loss: 0.1781, g_loss: 4.6586\n",
      "Epoch [9/10], d_loss: 0.0580, g_loss: 6.2682\n",
      "Epoch [10/10], d_loss: 0.2097, g_loss: 6.9569\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for images, _ in train_loader:\n",
    "        batch_size = images.size(0)\n",
    "        images = images.view(batch_size, -1).to(device) # doe een flatten\n",
    "        ones = torch.ones(batch_size, 1).to(device) \n",
    "        zeros = torch.zeros(batch_size, 1).to(device)\n",
    "        \n",
    "        # stap 1: eerste batch met true images door de discriminator\n",
    "        optimizer_D.zero_grad()\n",
    "        outputs = discriminator(images)\n",
    "        loss_d_real = criterion(outputs, ones)\n",
    "        loss_d_real.backward()\n",
    "        # optimizer.step() doe ik maar op het einde\n",
    "\n",
    "        # tweede stap: batch met fake images door de discriminator\n",
    "        noise = torch.rand(batch_size, latent_dim).to(device)\n",
    "        fake_images = generator(noise) # genereer fake beeldjes\n",
    "        outputs = discriminator(fake_images)\n",
    "        loss_d_fake = criterion(outputs, zeros)\n",
    "        loss_d_fake.backward()\n",
    "\n",
    "        optimizer_D.step() # pas hier de gewichten van de discriminator aan\n",
    "\n",
    "        loss_d = loss_d_fake + loss_d_real\n",
    "\n",
    "        # derde stap: train de generator\n",
    "        optimizer_G.zero_grad()\n",
    "        fake_images = generator(noise) # genereer fake beeldjes tweede keer (omdat na het uitvoeren van een backward de resources vrijgegeven worden\n",
    "        outputs = discriminator(fake_images) # gewichten descriminator aangepast dus opnieuw classificeren\n",
    "        loss_g = criterion(outputs, ones) # hier laten we ones staan want we wouden dat onze fakes echte waren\n",
    "        loss_g.backward()\n",
    "        optimizer_G.step()\n",
    "        \n",
    "    # Print verlies na elke epoch\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], d_loss: {loss_d.item():.4f}, g_loss: {loss_g.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bcff63-ec4a-46cb-a2c9-b559bbe75a04",
   "metadata": {},
   "source": [
    "## Visualiseren van de resultaten\n",
    "\n",
    "Deze cel definieert een functie om enkele gegenereerde afbeeldingen van de getrainde generator te visualiseren. Het genereert willekeurige ruis en laat de generator nieuwe afbeeldingen maken, die vervolgens worden weergegeven met behulp van Matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bd2e57ab-d145-4323-b05f-60ccedbb39b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x300 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Functie om gegenereerde afbeeldingen te visualiseren\n",
    "def show_generated_images(generator, latent_dim, num_images=5):\n",
    "    generator.eval()\n",
    "    noise = torch.randn(num_images, latent_dim).to(device)\n",
    "    with torch.no_grad():\n",
    "        generated_images = generator(noise).cpu().view(num_images, 28, 28)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, num_images, figsize=(15, 3))\n",
    "    for i in range(num_images):\n",
    "        axes[i].imshow(generated_images[i], cmap='gray')\n",
    "        axes[i].axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Visualiseer enkele gegenereerde afbeeldingen na training\n",
    "show_generated_images(generator, latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2df574-dfb4-4eb8-9924-5c7777782ce6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
