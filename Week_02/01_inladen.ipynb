{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zwBCE43Cv3PH"
   },
   "source": [
    "# Gestructureerde data: inladen dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YQB7yiF6v9GR"
   },
   "source": [
    "## Enkel datatype\n",
    "\n",
    "Er zijn heel veel verschillende bronnen om datasets te vinden. Je kan ze bijvoorbeeld op keras, overheidssites en dergelijke vinden.\n",
    "Ook zijn er heel wat datasets die standaard geworden zijn voor voorbeelden/modellen te testen. \n",
    "Deze datasets worden mee aangeleverd met de verschillende modelling-frameworks en kunnen zo eenvoudig gebruikt worden zonder een extra download uit te voeren.\n",
    "In deze notebook gaan we werken met deze standaard datasets.\n",
    "\n",
    "In het eerste voorbeeld gaan we werken met een dataset waarbij alle data reeds numeriek is, meer bepaald gaan we werken met de iris-dataset dat informatie over de bloemen van een aantal iris-soorten bevat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.3, 2.5, 5. , 1.9],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [5.1, 3.4, 1.5, 0.2]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = load_iris(return_X_y=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch\n",
    "\n",
    "Om een dataset in lezen en klaar te maken in pytorch moet je werken met een Dataset. Dit kan je doen als volgt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# dit bevat de preprocessing stappen dus heel sterk afhankelijk van de dataset waarmee je werkt\n",
    "class IrisDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X.values, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y.values, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # deze functie return de rij met index idx\n",
    "        return self.X[idx], self.y[idx] # return inputs, labels\n",
    "\n",
    "train_dataset = IrisDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras\n",
    "\n",
    "Keras is vooral bedoeld als uitvoerend framework en niet om data in te laden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mixed types\n",
    "\n",
    "Bovenstaande voorbeelden zijn eenvoudige voorbeelden omdat de data in principe reeds gepreprocessed is of uit slechts 1 datatype bestaat. \n",
    "Dit heeft als gevolg dat alle inputs op dezelfde manier verwerkt kunnen worden en er dus geen onderscheid gemaakt moet worden tussen verschillende kolommen.\n",
    "Data met hetzelfde type kan dus eenvoudig aan een sequentieel neuraal netwerk model gepresenteerd worden.\n",
    "\n",
    "Indien de dataset echter meerdere types bevatten kan de data niet rechtstreeks aan het neuraal netwerk doorgegeven worden aangezien dit type model enkel met numerieke data kan werken. \n",
    "Een standaard dataset waarin dit gebeurd is de titanic dataset.\n",
    "Hoe dit gebeurd in de verschillende frameworks zie je hieronder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch\n",
    "\n",
    "Aangezien we data binnenkrijgen in een dataset als numpy array/dataframe kunnen we in de constructor of de get_item functie de nodige preprocessing stappen uitvoeren.\n",
    "Hieronder doe ik het rechtstreeks met pandas, je kan het ook met een sci-kit learn pipeline doen.\n",
    "\n",
    "**Let op:** Hieronder splits ik niet op train en testdata dus kan ik de preprocessingen stappen in de constructor doen van de dataset.\n",
    "Indien er echter eerst een splitsing gebeurt in train- en testdata, dan moet je de preprocessing stappen in de test-data doen met de parameters geleerd uit de dataset.\n",
    "Dit is bijvoorbeeld belangrijk als er een klasse niet aanwezig is in de dataset. Dan zou deze niet gemapt worden en komt de ordinal encoding niet overeen tussen train- en testdata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "# Load Titanic dataset\n",
    "titanic = pd.read_csv(\"https://storage.googleapis.com/tf-datasets/titanic/train.csv\")\n",
    "\n",
    "# dit bevat de preprocessing stappen dus heel sterk afhankelijk van de dataset waarmee je werkt\n",
    "class TitanicDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        # null-waarden invullen\n",
    "        dataframe.fillna({'age': dataframe['age'].median()}, inplace=True)\n",
    "        dataframe.fillna({'embark_town': dataframe['embark_town'].mode()[0]}, inplace=True)\n",
    "        # ordinal encoding\n",
    "        dataframe['sex'] = dataframe['sex'].astype('category').cat.codes\n",
    "        dataframe['class'] = dataframe['class'].astype('category').cat.codes\n",
    "        dataframe['embark_town'] = dataframe['embark_town'].astype('category').cat.codes\n",
    "\n",
    "        X = dataframe['class', 'sex', 'age', 'n_siblings_spouses', 'parch', 'fare']\n",
    "        y = dataframe['survived']\n",
    "\n",
    "        self.X = torch.tensor(X_values, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y_values, dtype=torch.long)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # deze functie return de rij met index idx\n",
    "        return self.X[idx], self.y[idx] # return inputs, labels\n",
    "\n",
    "dataset = TitanicDataset(titanic) # hier moet je opletten, want hier is eigenlijk data leakage aanwezig (de mediaan)\n",
    "\n",
    "# nog splitsen in train_test\n",
    "train_size = int(0.8 *len(dataset))\n",
    "test_size = len(dataset)-train_size\n",
    "\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "pandas_dataframe.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
