{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zwBCE43Cv3PH"
   },
   "source": [
    "# Gestructureerde data: preprocessing dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In dit voorbeeld gaan we verder werken op de titanic dataset bestudeerd in voorgaande notebook.\n",
    "Hierbij gaan we preprocessing toevoegen of in meer detail bespreken.\n",
    "\n",
    "Hierbij is een belangrijk onderscheid tussen pytorch en tensorflow op te merken. Hierbij is het belangrijk om te realiseren dat pytorch verwacht dat alle data dat uit de __get__item functie komt numeriek is. Deze moet niet noodzakelijk reeds geschaald zijn maar moet wel dat datatype hebben. Het is dus belangrijk om een goede keuze te maken op welke plaats de nodige preprocessing stappen uitgevoerd worden. \n",
    "In het geval van tensorflow (in het geval van mixed datatypes) plaatsen we van in het begin elke feature apart. Daarna voegen we gelijkaardige features samen om deze te preprocessen. Pas op het einde van dit proces worden alle features samengevoegd tot een numerieke tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer # om null-waarden in te vullen\n",
    "\n",
    "# Load Titanic dataset\n",
    "titanic = pd.read_csv(\"https://storage.googleapis.com/tf-datasets/titanic/train.csv\")\n",
    "display(titanic)\n",
    "\n",
    "numeric_features = ['age', 'n_siblings_spouse', 'parch', 'fare']\n",
    "numeric_transformer= Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categoric_features = ['sex', 'class', 'embark_town', 'deck', 'alone']\n",
    "categoric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')), # median kan problemen geven met categorieke waarden\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numeric_transformer, numeric_features),\n",
    "    ('cat', categoric_transformer, categoric_features),\n",
    "\n",
    "# dit bevat de preprocessing stappen dus heel sterk afhankelijk van de dataset waarmee je werkt\n",
    "class TitanicDataset(Dataset):\n",
    "    def __init__(self, dataframe, preprocessor):\n",
    "        X = dataframe.drop('survived', axis=1)\n",
    "        y = dataframe['survived']\n",
    "\n",
    "        preprocessor.fit(X)\n",
    "        X = preprocessor.transform(X)\n",
    "\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y_values, dtype=torch.long)\n",
    "        self.preprocessor = preprocessor\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # deze functie return de rij met index idx\n",
    "        return self.X[idx], self.y[idx] # return inputs, labels\n",
    "\n",
    "titanic_train = df.sample(frac=0.8)\n",
    "titanic_test = titanic.drop(titanic_train.index)\n",
    "\n",
    "dataset_train = TitanicDataset(titanic_train, preprocessor)\n",
    "dataset_test = TitanicDataset(titanic_test, dataset_train.preprocessor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oefening: Inkomensdataset\n",
    "\n",
    "Met onderstaande code downloaden we een csv met gegevens rond het inkomen van volwassenen.\n",
    "Plaats in de code-cellen eronder de nodige code om de volgende preprocessingstappen uit te voeren met pytorch:\n",
    "\n",
    "* Splits in train-test\n",
    "* Label kolom is het inkomen -> voer hiervoor ordinal encoding uit\n",
    "* Voer normalisatie uit van de numerieke kolommen zodat alle waarden tussen 0 en 1 liggen (geen standaardverdeling)\n",
    "* Voer ordinal encoding uit op de occupation en native_country kolom\n",
    "* Voer one-hot encoding uit op de overige niet-numerieke kolommen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data'\n",
    "columns = ['age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital_status', \n",
    "           'occupation', 'relationship', 'race', 'sex', 'capital_gain', 'capital_loss', \n",
    "           'hours_per_week', 'native_country', 'income']\n",
    "adult_income = pd.read_csv(url, header=None, names=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "pandas_dataframe.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
