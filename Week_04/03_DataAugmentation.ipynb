{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ac16090",
   "metadata": {},
   "source": [
    "# Data augmentation\n",
    "\n",
    "Het verzamelen van voldoende data kan zeer tijdrovend en kostelijk zijn.\n",
    "Daarom zou het handig zijn om op een automatische manier extra data aan te maken.\n",
    "Dit is wat data augmentation doet en wordt vaak gebruikt wanneer er gewerkt wordt met visuele of auditieve data.\n",
    "De code hieronder zal vooral een voorbeeld zijn van hoe je data augmentatie kan toepassen op beelden/images.\n",
    "Hierbij gaan we voor het trainen op een random manier een variatie maken van de figuur.\n",
    "Doordat er meerdere epochs gebruikt worden bij training zullen er op die manier meerdere varianten van elke figuur gebruikt worden bij training.\n",
    "\n",
    "Data augmentation kan je meestal toepassen zonder problemen. Zeker de opties waarbij geen pixels verdwijnen geven normaal geen issues.\n",
    "Let echter wel op als je roteert of cropt en hetgene dat je moet detecteren aan de rand van je scherm ligt, dat dat object kan verdwijnen.\n",
    "Indien je genoeg epochs gebruikt zou dit echter geen groot probleem mogen zijn door compensatie in de andere epochs.\n",
    "\n",
    "In de vorige notebook hadden we onderstaande model om een classificatie CNN te maken. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20194191",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Stap 1: Dataset Inladen en Voorbereiden\n",
    "transform = transforms.Compose([ \n",
    "    transforms.ToTensor(),  # Zet de afbeelding om naar een tensor en normaliseer naar [0, 1]\n",
    "])\n",
    "\n",
    "# Laad de CIFAR-10 dataset\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=2)\n",
    "\n",
    "# Define the CNN model using torch.nn.Sequential\n",
    "model = nn.Sequential(\n",
    "    nn.Conv2d(3, 6, 5),       # Convolutional layer: input channels=3, output channels=6, kernel size=5\n",
    "    nn.ReLU(),                # ReLU activation\n",
    "    nn.MaxPool2d(2, 2),       # Max pooling layer: kernel size=2, stride=2\n",
    "    nn.Conv2d(6, 16, 5),      # Convolutional layer: input channels=6, output channels=16, kernel size=5\n",
    "    nn.ReLU(),                # ReLU activation\n",
    "    nn.MaxPool2d(2, 2),       # Max pooling layer: kernel size=2, stride=2\n",
    "    nn.Flatten(),             # Flatten the output for the fully connected layers\n",
    "    nn.Linear(16 * 5 * 5, 120), # Fully connected layer: input features=16*5*5, output features=120\n",
    "    nn.ReLU(),                # ReLU activation\n",
    "    nn.Linear(120, 84),       # Fully connected layer: input features=120, output features=84\n",
    "    nn.ReLU(),                # ReLU activation\n",
    "    nn.Linear(84, 10)         # Output layer: input features=84, output features=10 (number of classes)\n",
    ").to(device)\n",
    "\n",
    "# Define a loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(2):  # Number of epochs\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:  # Print every 2000 batches\n",
    "            print(f'[Epoch {epoch + 1}, Batch {i + 1}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "# Evaluate the model\n",
    "dataiter = iter(testloader)\n",
    "images, labels = next(dataiter)\n",
    "images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "# Make predictions\n",
    "outputs = model(images)\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "# Print the image, true labels, and predicted labels\n",
    "def imshow(img):\n",
    "    img = img.permute(1, 2, 0).numpy()  # Convert back to HxWxC\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "\n",
    "# Print images\n",
    "imshow(torchvision.utils.make_grid(images.cpu()))\n",
    "print('GroundTruth: ', ' '.join(f'{trainset.classes[labels[j]]:5s}' for j in range(4)))\n",
    "print('Predicted:  ', ' '.join(f'{trainset.classes[predicted[j]]:5s}' for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec61a0a9-91af-4f12-8013-8c5667a8d816",
   "metadata": {},
   "source": [
    "Om op de cifar10 dataset data augmentation uit te voeren moeten we enkel de transform stappenplan aanpassen om op een random manier bewerkingen uit te voeren op de figuren.\n",
    "We kunnen bijvoorbeeld de transform aanpassen als volgt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf52cb34",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transforms' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m transform \u001b[38;5;241m=\u001b[39m \u001b[43mtransforms\u001b[49m\u001b[38;5;241m.\u001b[39mCompose([ \n\u001b[1;32m      2\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mRandomHorizontalFlip(),\n\u001b[1;32m      3\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mRandomVerticalFlip(),\n\u001b[1;32m      4\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mColorJitter(brightness\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, contrast\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, saturation\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, hue\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m),\n\u001b[1;32m      5\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mToTensor(),  \u001b[38;5;66;03m# Zet de afbeelding om naar een tensor en normaliseer naar [0, 1]\u001b[39;00m\n\u001b[1;32m      6\u001b[0m ])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'transforms' is not defined"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([ \n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "    transforms.ToTensor(),  # Zet de afbeelding om naar een tensor en normaliseer naar [0, 1]\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7db909-c56a-40d0-b251-87b26c4c479c",
   "metadata": {},
   "source": [
    "## Keras\n",
    "\n",
    "De analoge oplossing om dit te doen met keras is door het model in onderstaande voorbeeld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9dc4ca7-ea3d-4010-a6e8-8d2dbb745f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras_core as keras\n",
    "from keras_core import Sequential\n",
    "from keras_core import layers\n",
    "\n",
    "# Laad en bereid de CIFAR-10 dataset voor\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "# Min-Max scaling naar [0, 1]\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "# Definieer het CNN-model met tf.keras.Sequential\n",
    "model = Sequential([\n",
    "    layers.Rescaling(1.0/255.0),\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile het model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train het model\n",
    "history = model.fit(x_train, y_train, epochs=10, batch_size=64,\n",
    "                    validation_split=0.1, verbose=2)\n",
    "\n",
    "# Evalueer het model\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(f'\\nTest accuracy: {test_acc:.4f}')\n",
    "\n",
    "# Maak voorspellingen\n",
    "predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5815101d-25da-4c2b-a608-853f5c2d03d1",
   "metadata": {},
   "source": [
    "aan te passen op de volgende manier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f008e2b-1535-4a16-af3d-98b141b387d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential([\n",
    "    # Data Augmentation Layers\n",
    "    layers.RandomFlip(\"horizontal\"),          # Willekeurig horizontaal flippen van de afbeeldingen\n",
    "    layers.RandomRotation(0.1),               # Willekeurig roteren van de afbeeldingen met maximaal 10%\n",
    "    layers.RandomZoom(0.1),                   # Willekeurig zoomen in de afbeeldingen met maximaal 10%\n",
    "    layers.RandomContrast(0.1),               # Willekeurig aanpassen van het contrast met maximaal 10%\n",
    "    \n",
    "    # Convolutionele Lagen\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    \n",
    "    # Fully Connected Layers\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc62b48-a960-4066-b9d2-dbd4d26ef213",
   "metadata": {},
   "source": [
    "# Oefening: Data Augmentation met Keras Core\n",
    "\n",
    "In deze oefening gaan we het concept van **data augmentation** oefenen. Je gebruikt de **CIFAR-10 dataset** en probeert verschillende augmentaties toe te passen op de trainingsbeelden. \n",
    "Voer de volgende stappen uit:\n",
    "\n",
    "* Laad de CIFAR-10 dataset\n",
    "* Definieer een aantal data augmentation layers\n",
    "  - Rotatie van de afbeeldingen: willekeurige rotatie tussen -15 graden en +20 graden\n",
    "  - Horizontale flip: afbeeldingen af en toe horizontaal spiegelen (kans van 30%)\n",
    "  - Translatie in hoogte en breedte: verschuiving tot 10% van de hoogte en 10% van de breedte\n",
    "  - Variatie in helderheid: helderheid aanpassen met een factor tussen 0.8 en 1.2\n",
    "  - Pas een contrast-aanpassing toe zodat sommige beelden iets hoger of lager contrast hebben\n",
    "* Pas de augmentaties toe op een willekeurige batch en toon 10 figuren voor en na augmentatie\n",
    "  \n",
    "**Extra opdrachten**\n",
    "\n",
    "* Experimenteer met verschillende waarden voor de parameters van de augmentaties.\n",
    "* Voeg meer augmentaties toe zoals RandomZoom, RandomCrop, RandomContrast (eventueel met een custom layer).\n",
    "* Observeer hoe de augmented afbeeldingen eruit zien en noteer welke augmentaties het meest effectief lijken voor training van een CNN.\n",
    "* Wat is het effect van de data augmentatie op de prestaties van het bovenstaande model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe292bd-d872-438b-89a4-080dcc60524b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243e7115-36e5-42d5-9aab-e59581be867b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "d5e8e3a19af5ceb2434683dff87da6345c3b29f7eb0a8a138558c07d014a01cc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
