{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "429d571c",
   "metadata": {},
   "source": [
    "# Neuraal netwerk oefening: Nintendo games\n",
    "\n",
    "In deze opgave gaan we een aantal eenvoudige neurale netwerken maken om de basisfunctionaliteit in te oefenen van Torch en Keras. Hierbij focussen we vooral op de processing stappen, het opstellen van de netwerkarchitectuur en de trainingsstap.\n",
    "Het is hierbij niet noodzakelijk om op zoek te gaan naar de beste architectuur.\n",
    "\n",
    "**Dien de opgave in door het te pushen naar de main branch op github en vergeet niet op de vragen te beantwoorden. Laat je output staan om eenvoudiger je resultaten te kunnen verifieren. Vergeet ook de vragen niet te beantwoorden**\n",
    "\n",
    "## Downloaden en inladen data\n",
    "\n",
    "Schrijf in onderstaande cell alle uit te voeren imports die nodig zijn doorheen deze notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779c1a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schrijf alle imports in deze blok\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e265ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install kagglehub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63aac1d",
   "metadata": {},
   "source": [
    "In deze opgave maken we gebruik van een dataset over Nintendo games.\n",
    "We gaan deze dataset gebruiken om de gebrukersscore te voorspellen die een bepaald spel gaat behalen.\n",
    "\n",
    "Maak gebruik van de tensorflow get_file om de volgende file te downloaden:\n",
    "* https://www.kaggle.com/datasets/joebeachcapital/nintendo-games\n",
    "\n",
    "Dit is een dataset van kaggle dus gebruik de opendatasets library zoals gezien in data science"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4eacc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# downloaden datasets\n",
    "import kagglehub\n",
    "\n",
    "path = kagglehub.dataset_download('joebeachcapital/nintendo-games') # het path is waar de dataset gedownload is\n",
    "\n",
    "df = pd.read_csv(f\"{path}/NintendoGames.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a4ddb8",
   "metadata": {},
   "source": [
    "Lees deze datasets in (met behulp van panda) en als dataframe.\n",
    "Print de eerste 5 rijen uit.\n",
    "\n",
    "**Welke kolommen zijn in deze dataset de features en welke de targets/labels? Welke kolommen zou je niet gebruiken en waarom?**\n",
    "Maak lijsten aan voor de namen van de feature-kolommen en label kolom."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e2249a",
   "metadata": {},
   "source": [
    "Antwoord: ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bd63b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.head())\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd85b843",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "Bereken voor de dataset de volgende statistieken met behulp van pandas:\n",
    "* Hoeveel platformen zijn er aanwezig in de dataset\n",
    "* Hoeveel games hebben geen user-score? Drop deze rijen ook.\n",
    "* Maak een figuur om te tonen hoeveel games er ontwikkeld zijn voor elk platform.\n",
    "* Hoeveel null waarden zijn er per kolom? Vul de numerieke kolommen aan met 0 en de categorieke kolommen met 'unknown'.\n",
    "* Is de genres en developer kolom een string of een lijst? Zijn ze beide hetzelfde type? Hoe heb je dit gecontroleerd? Pas de kolommen met de apply-functie aan zodat beide kolommen een tekstveld zijn gesplitst door het ',' symbool.\n",
    "* Hoeveel unieke developers zijn er die nintendo games maken? Wat zijn de 5 developers die aan het meeste games gewerkt hebben? Maak hiervoor een figuur.\n",
    "\n",
    "\n",
    "**Antwoord vraag 5:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e84193",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Vraag 1\n",
    "df.platform.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7dd9b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vraag 2\n",
    "nans = df.isna().user_score\n",
    "print('aantal nuns', nans.sum())\n",
    "df2 = df[~nans]\n",
    "print('aantal rijen overgebleven', len(df2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcb18c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vraag 3\n",
    "df2.groupby('platform').size().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6cc844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vraag 4\n",
    "df2.isna().sum()\n",
    "df3 = df2.fillna({'meta_score': 0, 'esrb_rating': 'unknown'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2994a6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vraag 5\n",
    "print(df3.genres.iloc[0], type(df3.genres.iloc[0]))\n",
    "print(df3.developers.iloc[0], type(df3.developers.iloc[0]))\n",
    "\n",
    "df4 = df3.copy()\n",
    "df4.genres = df3.genres.str.strip(\"[]\").str.replace(\"'\", \"\", regex=False)\n",
    "df4.developers = df3.developers.str.strip(\"[]\").str.replace(\"'\", \"\", regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ebf413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vraag 6\n",
    "tmp = df4.developers.str.split(', ').explode()\n",
    "print('aantal unieke developers', tmp.nunique())\n",
    "\n",
    "tmp.value_counts().head(5).plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad9697e",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07f4852",
   "metadata": {},
   "source": [
    "Voer nu de volgende stappen uit om de beschikbare data zo bruikbaar mogeljk te maken. **Gebruik de user_score als target.**\n",
    "* Splits de dataset in training en testdata. Gebruik 10% van de data als testdata. Tip: bekijk de sample functie in pandas. Zorg ervoor dat rijen met ontbrekende waarden niet gebruikt worden.\n",
    "* Maak een trainings- en testdataset aan gebruik makende van de Dataset klasse van PyTorch. Zorg er hierbij voor dat de volgende features gebruikt worden: platform, meta_score, esrb_rating, developers, genres. Natuurlijk moet het target ook meegegeven worden bij het aanmaken van de dataset. Zorg ervoor dat de nodige preprocessing stappen uitgevoerd worden:\n",
    "    * Maak nu de nodige preprocessing stappen aan voor de types data:\n",
    "        * numeriek -> normalisatie\n",
    "        * categoriek -> one-hot encoding\n",
    "        * tekst -> multi-hot encoding\n",
    "* Maak daarna Dataloaders aan en zorg er hierbij voor dat alle elementen geshuffeld worden, maak daarna batches van 4 elementen.\n",
    "\n",
    "**Vraag: Je hebt hiervoor het aantal unieke developers berekend. Kan je uit de figuur afleiden of dit aantal klopt? Hoe doe je dit? Verwijs hierbij naar de gemaakte figuur.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fd781a",
   "metadata": {},
   "source": [
    "**Antwoord:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd1382f-8f7f-4c66-bdf2-4f1838b1568f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fd064c-66b6-495d-9063-dc246eddd9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, FunctionTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "numeric_features = ['meta_score']\n",
    "categorical_features = ['platform', 'esrb_rating']\n",
    "tekst_features = ['developers', 'genres']\n",
    "\n",
    "numeric_pipeline = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_pipeline = Pipeline(steps=[\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "text_pipeline = Pipeline(steps=[\n",
    "    ('flatten', FunctionTransformer(lambda x: x.iloc[:, 0].values, validate=False)),\n",
    "    ('encoder', CountVectorizer(tokenizer=lambda s: s.split(','))) # splits de developers op de komma -> tel elke developer\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numeric_pipeline, numeric_features),\n",
    "    ('cat', categorical_pipeline, categorical_features),\n",
    "    ('text', text_pipeline, tekst_features)\n",
    "])\n",
    "\n",
    "\n",
    "# dit bevat de preprocessing stappen dus heel sterk afhankelijk van de dataset waarmee je werkt\n",
    "class NintendoDataset(Dataset):\n",
    "    def __init__(self, dataframe, preprocessor=None, train=False):\n",
    "        X = dataframe.drop('user_score', axis=1)\n",
    "        y = dataframe['user_score']\n",
    "\n",
    "        if train:\n",
    "            preprocessor.fit(X)\n",
    "        X = preprocessor.transform(X).toarray()\n",
    "\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y.values, dtype=torch.long)\n",
    "        self.preprocessor = preprocessor\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # deze functie return de rij met index idx\n",
    "        return self.X[idx], self.y[idx] # return inputs, labels\n",
    "\n",
    "nintendo_train = df4.sample(frac=0.9)\n",
    "nintendo_test = df4.drop(nintendo_train.index)\n",
    "\n",
    "dataset_train = NintendoDataset(nintendo_train, preprocessor, train=True)\n",
    "dataset_test = NintendoDataset(nintendo_test, dataset_train.preprocessor)\n",
    "\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=32, shuffle=True)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcc8df6",
   "metadata": {},
   "source": [
    "## Modelling\n",
    "\n",
    "Maak nu met behulp van **Pytorch** de volgende modellen aan, train ze en evalueer ze aan de hand van de trainingsdata:\n",
    "* Lineaire regressie\n",
    "* Neuraal netwerk bestaande uit 1 hidden laag met 3 neuronen\n",
    "* Neuraal netwerk bestaande uit 3 hidden lagen met respectievelijk 10, 5 en 5 neuronen.\n",
    "* Neuraal netwerk bestaande uit 3 hidden lagen met respectievelijk 10, 5 en 5 neuronen met dropout.\n",
    "* Neuraal netwerk bestaande uit 3 hidden lagen met respectievelijk 10, 5 en 5 neuronen met L1 regularisatie.\n",
    "* Neuraal netwerk bestaande uit 3 hidden lagen met respectievelijk 10, 5 en 5 neuronen met L2 regularisatie.\n",
    "\n",
    "Maak zoveel mogelijk gebruik van functies om repititieve zaken te verbergen.\n",
    "Maak daarnaast ook gebruik van de **plot_loss** functie om de geschiedenis van het trainen te visualiseren.\n",
    "\n",
    "**Bespreek hieronder je observaties. Welke loss functie heb je gebruikt? Waarom heb je voor deze functie gekozen? Welke hyperparameters heb je uitgeprobeerd? Welk model werkt goed, welk niet? Welk is aan het overfitten, welk aan het underfitten? Bespreek de gebruikte parameters van de verschillende lagen van het laatste model. Waarom heb je de waarde gekozen voor die parameters?\n",
    "Verwijs hierbij naar de figuren en de behaalde loss-waarden voor de testdata.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75f4904",
   "metadata": {},
   "source": [
    "Antwoord ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839e102e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss over epochs\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "def plot_loss(loss_history):\n",
    "    plt.plot(loss_history, label=\"Training Loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e361a804-53ca-4d3f-ba64-db6957d48c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "for inputs, labels in dataloader_train:\n",
    "    print(inputs.shape, labels.shape)\n",
    "    break\n",
    "\n",
    "inputs, labels = next(iter(dataloader_train)) # met next(iter()) haal je de eerste batch ook op\n",
    "print(inputs.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794c919e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Neuraal netwerk bestaande uit 3 hidden lagen met respectievelijk 10, 5 en 5 neuronen met dropout.\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(191, 10),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(10, 5),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(5, 5),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(5, 1)\n",
    ")\n",
    "\n",
    "#L1 regularisatie: mseloss + l1loss voor backwardspropagation\n",
    "#L2 regularisatie: weight decay in adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507d41e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967e0d28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48892e2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c72a566",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31551de4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c17ce6-0307-4119-b165-e7ff6a747c5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
